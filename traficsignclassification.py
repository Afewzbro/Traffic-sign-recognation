# -*- coding: utf-8 -*-
"""TraficSignClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jIQ_PYJp3HUM6m4r0LlivPir2DZfO4ez
"""

!pip install numpy
!pip install tensorflow
!pip install sklearn
!pip install matplotlib
!pip install pandas
!pip install scikit-learn

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import seaborn as sns
from PIL import Image
import os
from pathlib import Path
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt

class LearningRateTracker(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        logs['learning_rate'] = tf.keras.backend.get_value(self.model.optimizer.learning_rate)

data_path = Path('/content/drive/MyDrive/GTSRB')

data = []
labels = []
classes = 43

#Retrieving the images and their labels 
for i in range(classes):
    path = data_path / 'Train' / str(i)
    images = os.listdir(path)

    for img in images:
        try:
            image = Image.open(path / img)
            image = image.resize((30,30))
            image = np.array(image)
            data.append(image)
            labels.append(i)
        except Exception as e:
            print("Error loading image:", e)

#Converting lists into numpy arrays
data = np.array(data)
labels = np.array(labels)

# Step 3: Splitting the data into train and test
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# Step 4: Build the model
model = Sequential()
model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))
model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(rate=0.25))
model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(rate=0.25))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(rate=0.5))
model.add(Dense(43, activation='softmax'))

# Step 5: Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Create LearningRateTracker instance
lr_tracker = LearningRateTracker()

# Step 6: Train the model
epochs = 15
history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))

# Step 7: Plotting graphs for accuracy 
import matplotlib.pyplot as plt
plt.figure(0)
plt.plot(history.history['accuracy'], label='training accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

# Step 8: Confusion matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion matrix')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.show()

# Step 10: Test with a new image
def test_image(path):
    img = Image.open(path).convert('RGB')
    img = img.resize((30,30))
    img = np.array(img)
    img = img.reshape(1, 30, 30, 3)
    pred = np.argmax(model.predict(img), axis=-1)[0]
    return pred

# Replace 'path_to_your_image' with the actual path of the image you want to test
print("Predicted class is: ", test_image('/content/Screenshot from 2023-06-06 06-17-39.png'))